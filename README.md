# ML_Forkway_NLTK

Модель разработана для обработки текстовых данных с использованием библиотеки **NLTK** (Natural Language Toolkit) на Python. Модель извлекает полезную информацию из набора данных, содержащих описания вакансий, для последующего анализа и классификации. Модель содеридт предварительную обработку текста, такие как удаление HTML-тегов, стоп-слов, нормализацию текста через лемматизацию, а также применение методов анализа текста для дальнейшей работы с данными.

## План разработки модели

1. **Загрузка и предобработка данных**: Чтение данных из Excel-файла, содержащего описания вакансий, и выделение нужных столбцов (`id` и `description`).
2. **Очистка текста**: Удаление HTML-тегов, ненужных символов и стоп-слов для улучшения качества анализа.
3. **Нормализация текста**: Лемматизация для приведения слов к базовой форме, что позволяет уменьшить количество уникальных токенов и улучшить точность последующих моделей машинного обучения.
4. **Анализ текста**: Применение различных методов анализа текста, включая токенизацию, лемматизацию и частотный анализ, для подготовки данных к последующей работе.

## Технологии и инструменты

- **Python**: Основной язык программирования.
- **Pandas**: Библиотека для обработки и анализа данных.
- **Numpy**: Библиотека для научных вычислений.
- **Re**: Регулярные выражения для очистки текста.
- **Json**: Для работы с JSON-данными.
- **NLTK**: Natural Language Toolkit для анализа текста.

## Структура проекта

1. **Загрузка необходимых библиотек и модулей**:
   ```python
   import numpy as np
   import pandas as pd
   import re
   import json
   ```

2. **Использование NLTK**:
   ```python
   from nltk.corpus import stopwords
   from nltk.tokenize import word_tokenize
   from nltk.stem import WordNetLemmatizer
   import nltk
   ```

3. **Подключение Google Drive**:
   ```python
   from google.colab import drive
   drive.mount("/content/drive")
   ```

4. **Чтение данных из Excel-файла**:
   ```python
   df = pd.read_excel('/content/drive/MyDrive/Forkway/2023-01-01-2023-01-10.xlsx')
   data = df[['id', 'description']]
   ```

5. **Предварительная обработка текста**:
   - Удаление HTML-тегов.
   - Токенизация текста.
   - Лемматизация с помощью `WordNetLemmatizer`.
   - Удаление стоп-слов.

6. **Анализ текста**:
   - Частотный анализ ключевых слов.
   - Визуализация результатов.

## Как запустить проект

1. **Установите необходимые зависимости**:
   ```bash
   pip install pandas numpy nltk
   ```

2. **Загрузите необходимые ресурсы для NLTK**:
   ```python
   nltk.download('stopwords')
   nltk.download('wordnet')
   nltk.download('punkt_tab')
   ```

3. **Запустите проект**:
   - Загрузите файл с данными на Google Диск.
   - Подключитесь к Google Drive в блокноте Google Colaboratory.
   - Измените путь к файлу данных в соответствующем месте кода.
   - Запустите ячейки по порядку для выполнения всех шагов обработки данных.

## Результаты

Модель позволяет эффективно обрабатывать большие объемы текстовых данных, очищая их от шумов и нормализуя текст для дальнейшего анализа. Это может быть полезно для задач автоматического извлечения информации, кластеризации вакансий, рекомендаций кандидатов и многого другого. Данная моедель обрбатывает 952 строки за 5.49 секундды.

